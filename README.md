# ‚ö° Voxly - Instant Transcripts

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Chrome Extension](https://img.shields.io/badge/Chrome-Extension-green.svg)](https://developer.chrome.com/docs/extensions/)

**Transform audio & video into AI-ready transcripts. Instant YouTube extraction or local Whisper transcription.** 100% privacy-focused - runs entirely on your machine.

<p align="center">
  <img src="https://img.shields.io/badge/Powered%20by-OpenAI%20Whisper-orange" alt="Powered by Whisper">
  <img src="https://img.shields.io/badge/Speaker%20ID-pyannote.audio-purple" alt="Speaker diarization">
</p>

---

## ‚ú® Features

| Feature | Description |
|---------|-------------|
| ‚ö° **YouTube Instant** | Extract YouTube transcripts instantly (<1 sec) - no downloading needed! |
| üìÅ **File Upload** | Transcribe audio/video files (MP3, WAV, M4A, MP4, FLAC, etc.) |
| üîó **URL Support** | Transcribe from YouTube, Spotify, podcasts, and 30+ streaming sites |
| üé¨ **Tab Recording** | Record and transcribe audio playing in browser tabs |
| üë• **Speaker Diarization** | Identify who is speaking (optional, requires free Hugging Face account) |
| üé§ **Whisper Models** | Choose accuracy vs. speed with different Whisper models |
| üîí **100% Local** | All processing happens on your machine - complete privacy |
| ‚úèÔ∏è **Edit & Export** | Edit transcripts in-app, export as TXT, Markdown, JSON, SRT, or WebVTT |

---

## üñ•Ô∏è Screenshots

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  ‚ö° Voxly                           ‚îÇ
‚îÇ  Instant Transcripts                ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ URL ‚îÇ ‚îÇ File ‚îÇ ‚îÇRecord this Tab‚îÇ ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  ‚ö° YouTube transcript available!   ‚îÇ
‚îÇ  Extract instantly or use Whisper   ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  üîó [https://youtube.com/...]       ‚îÇ
‚îÇ                                     ‚îÇ
‚îÇ  [‚ö° Extract Instant] [üé§ Whisper]  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã Requirements

- **Python 3.9** or higher
- **ffmpeg** (for audio conversion)
- **Google Chrome** browser

---

## üöÄ Quick Start

### 1. Download

```bash
git clone https://github.com/outerbanks73/speaktotext-local.git
cd speaktotext-local
```

Or [download the ZIP](https://github.com/outerbanks73/speaktotext-local/archive/refs/heads/main.zip) and extract it.

### 2. Install

**macOS / Linux:**
```bash
./install.sh
```

**Windows:**
```batch
install.bat
```

This will:
- Create a Python virtual environment
- Install all dependencies (Whisper, pyannote, etc.)
- Create a launcher script

### 3. Start the Server

```bash
./start-server.sh      # macOS/Linux
start-server.bat       # Windows
```

The server runs on `http://localhost:5123`

### 4. Install Browser Extension

#### Chrome
1. Open Chrome and go to `chrome://extensions`
2. Enable **"Developer mode"** (toggle in top right)
3. Click **"Load unpacked"**
4. Select the `extension` folder from this project

#### Safari (macOS only)
1. Run the build script:
   ```bash
   ./build-safari.sh
   ```
2. Open the generated Xcode project:
   ```bash
   open "safari-extension/Voxly/Voxly.xcodeproj"
   ```
3. Select your Development Team in Signing & Capabilities
4. Build and Run (‚åòR)
5. Enable in Safari ‚Üí Preferences ‚Üí Extensions

**Note:** Tab recording is not available in Safari (browser API limitation).

### 5. Use It!

1. Click the Voxly icon in your browser toolbar
2. Choose your input method (File, URL, or Record Tab*)
3. Select a Whisper model
4. Click Transcribe
5. Copy or download your transcript

*Tab recording is Chrome-only

---

## üë• Enable Speaker Diarization (Optional)

To identify different speakers in your audio:

1. Create a free account at [huggingface.co](https://huggingface.co/join)
2. Go to [Settings ‚Üí Access Tokens](https://huggingface.co/settings/tokens)
3. Create a new token with **"Read"** access
4. Accept the model terms at [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
5. In the extension, click **Settings** and paste your token

---

## üéõÔ∏è Whisper Models

| Model | Speed | Accuracy | Memory |
|-------|-------|----------|--------|
| `tiny` | ‚ö°‚ö°‚ö°‚ö°‚ö° | ‚≠ê | ~1GB |
| `base` | ‚ö°‚ö°‚ö°‚ö° | ‚≠ê‚≠ê | ~1GB |
| `small` | ‚ö°‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê | ~2GB |
| `medium` | ‚ö°‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê | ~5GB |
| `large` | ‚ö° | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ~10GB |

**Recommendation:** Start with `base` for a good balance. Use `tiny` for quick drafts, `medium` or `large` for important transcriptions.

---

## üîß Manual Installation

If the installer doesn't work, you can set up manually:

```bash
# Create virtual environment
cd server
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start server
python server.py
```

---

## üêõ Troubleshooting

### "Server not running"
Make sure you've started the server with `./start-server.sh`

### "Address already in use"
Another process is using port 5123. Kill it with:
```bash
lsof -ti:5123 | xargs kill -9   # macOS/Linux
netstat -ano | findstr :5123    # Windows (then kill the PID)
```

### Slow transcription
- Use a smaller model (`tiny` or `base`)
- Apple Silicon Macs automatically use GPU acceleration

### ffmpeg errors
Make sure ffmpeg is installed:
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html and add to PATH
```

### Speaker diarization not working
1. Verify your Hugging Face token is correct
2. Make sure you accepted the model terms at the pyannote link
3. Check the server console for error messages

---

## üìÅ Project Structure

```
speaktotext-local/
‚îú‚îÄ‚îÄ extension/           # Chrome extension
‚îÇ   ‚îú‚îÄ‚îÄ manifest.json
‚îÇ   ‚îú‚îÄ‚îÄ popup.html/js    # Main UI
‚îÇ   ‚îú‚îÄ‚îÄ options.html/js  # Settings page
‚îÇ   ‚îú‚îÄ‚îÄ background.js
‚îÇ   ‚îî‚îÄ‚îÄ icons/
‚îú‚îÄ‚îÄ safari-extension/    # Safari extension
‚îÇ   ‚îú‚îÄ‚îÄ manifest.json    # Safari-compatible manifest
‚îÇ   ‚îî‚îÄ‚îÄ README.md        # Safari build instructions
‚îú‚îÄ‚îÄ server/
‚îÇ   ‚îú‚îÄ‚îÄ server.py        # FastAPI server (job management, downloads)
‚îÇ   ‚îú‚îÄ‚îÄ worker.py        # Isolated transcription subprocess
‚îÇ   ‚îî‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ install.sh           # macOS/Linux installer
‚îú‚îÄ‚îÄ install.bat          # Windows installer
‚îú‚îÄ‚îÄ build-safari.sh      # Safari extension builder
‚îú‚îÄ‚îÄ update.sh            # Update script
‚îî‚îÄ‚îÄ start-server.sh      # Server launcher
```

---

## üõ°Ô∏è Privacy

**Your audio never leaves your machine.**

- All transcription is done locally using OpenAI Whisper
- Speaker diarization runs locally using pyannote.audio
- The only external connection is to Hugging Face to download model weights (one-time)
- URL transcription uses yt-dlp to download audio locally before processing

---

## ü§ù Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## üìÑ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## üôè Credits

- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) - Speaker diarization
- [FastAPI](https://fastapi.tiangolo.com/) - API server
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - URL audio extraction

---

<p align="center">
  Made with ‚ù§Ô∏è for privacy-conscious transcription
</p>
