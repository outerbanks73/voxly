# ğŸ™ï¸ SpeakToText Local

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/)
[![Chrome Extension](https://img.shields.io/badge/Chrome-Extension-green.svg)](https://developer.chrome.com/docs/extensions/)

**A privacy-focused audio transcription Chrome extension that runs entirely on your machine.** No audio is ever sent to external servers.

<p align="center">
  <img src="https://img.shields.io/badge/Powered%20by-OpenAI%20Whisper-orange" alt="Powered by Whisper">
  <img src="https://img.shields.io/badge/Speaker%20ID-pyannote.audio-purple" alt="Speaker diarization">
</p>

---

## âœ¨ Features

| Feature | Description |
|---------|-------------|
| ğŸ“ **File Upload** | Transcribe audio/video files (MP3, WAV, M4A, MP4, FLAC, etc.) |
| ğŸ”— **URL Support** | Transcribe from YouTube, podcasts, and other audio URLs |
| ğŸ¬ **Tab Recording** | Record and transcribe audio playing in browser tabs |
| ğŸ‘¥ **Speaker Diarization** | Identify who is speaking (optional, requires free Hugging Face account) |
| âš¡ **Multiple Models** | Choose accuracy vs. speed with different Whisper models |
| ğŸ”’ **100% Local** | All processing happens on your machine - complete privacy |

---

## ğŸ–¥ï¸ Screenshots

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ™ï¸ SpeakToText Local              â”‚
â”‚  Private audio transcription        â”‚
â”‚                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚File â”‚ â”‚ URL â”‚ â”‚Record Tab â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                                     â”‚
â”‚  ğŸ“ Click or drag file here         â”‚
â”‚                                     â”‚
â”‚  Model: [Base (recommended) â–¼]      â”‚
â”‚                                     â”‚
â”‚  [    Transcribe File    ]          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“‹ Requirements

- **Python 3.9** or higher
- **ffmpeg** (for audio conversion)
- **Google Chrome** browser

---

## ğŸš€ Quick Start

### 1. Download

```bash
git clone https://github.com/outerbanks73/speaktotext-local.git
cd speaktotext-local
```

Or [download the ZIP](https://github.com/outerbanks73/speaktotext-local/archive/refs/heads/main.zip) and extract it.

### 2. Install

**macOS / Linux:**
```bash
./install.sh
```

**Windows:**
```batch
install.bat
```

This will:
- Create a Python virtual environment
- Install all dependencies (Whisper, pyannote, etc.)
- Create a launcher script

### 3. Start the Server

```bash
./start-server.sh      # macOS/Linux
start-server.bat       # Windows
```

The server runs on `http://localhost:5123`

### 4. Install Chrome Extension

1. Open Chrome and go to `chrome://extensions`
2. Enable **"Developer mode"** (toggle in top right)
3. Click **"Load unpacked"**
4. Select the `extension` folder from this project

### 5. Use It!

1. Click the SpeakToText Local icon in Chrome toolbar
2. Choose your input method (File, URL, or Record Tab)
3. Select a Whisper model
4. Click Transcribe
5. Copy or download your transcript

---

## ğŸ‘¥ Enable Speaker Diarization (Optional)

To identify different speakers in your audio:

1. Create a free account at [huggingface.co](https://huggingface.co/join)
2. Go to [Settings â†’ Access Tokens](https://huggingface.co/settings/tokens)
3. Create a new token with **"Read"** access
4. Accept the model terms at [pyannote/speaker-diarization-3.1](https://huggingface.co/pyannote/speaker-diarization-3.1)
5. In the extension, click **Settings** and paste your token

---

## ğŸ›ï¸ Whisper Models

| Model | Speed | Accuracy | Memory |
|-------|-------|----------|--------|
| `tiny` | âš¡âš¡âš¡âš¡âš¡ | â­ | ~1GB |
| `base` | âš¡âš¡âš¡âš¡ | â­â­ | ~1GB |
| `small` | âš¡âš¡âš¡ | â­â­â­ | ~2GB |
| `medium` | âš¡âš¡ | â­â­â­â­ | ~5GB |
| `large` | âš¡ | â­â­â­â­â­ | ~10GB |

**Recommendation:** Start with `base` for a good balance. Use `tiny` for quick drafts, `medium` or `large` for important transcriptions.

---

## ğŸ”§ Manual Installation

If the installer doesn't work, you can set up manually:

```bash
# Create virtual environment
cd server
python3 -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Start server
python server.py
```

---

## ğŸ› Troubleshooting

### "Server not running"
Make sure you've started the server with `./start-server.sh`

### "Address already in use"
Another process is using port 5123. Kill it with:
```bash
lsof -ti:5123 | xargs kill -9   # macOS/Linux
netstat -ano | findstr :5123    # Windows (then kill the PID)
```

### Slow transcription
- Use a smaller model (`tiny` or `base`)
- Apple Silicon Macs automatically use GPU acceleration

### ffmpeg errors
Make sure ffmpeg is installed:
```bash
# macOS
brew install ffmpeg

# Ubuntu/Debian
sudo apt install ffmpeg

# Windows
# Download from https://ffmpeg.org/download.html and add to PATH
```

### Speaker diarization not working
1. Verify your Hugging Face token is correct
2. Make sure you accepted the model terms at the pyannote link
3. Check the server console for error messages

---

## ğŸ“ Project Structure

```
speaktotext-local/
â”œâ”€â”€ extension/           # Chrome extension
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ popup.html/js    # Main UI
â”‚   â”œâ”€â”€ options.html/js  # Settings page
â”‚   â”œâ”€â”€ background.js
â”‚   â””â”€â”€ icons/
â”œâ”€â”€ server/
â”‚   â”œâ”€â”€ server.py        # FastAPI server
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ install.sh           # macOS/Linux installer
â”œâ”€â”€ install.bat          # Windows installer
â””â”€â”€ start-server.sh      # Server launcher
```

---

## ğŸ›¡ï¸ Privacy

**Your audio never leaves your machine.**

- All transcription is done locally using OpenAI Whisper
- Speaker diarization runs locally using pyannote.audio
- The only external connection is to Hugging Face to download model weights (one-time)
- URL transcription uses yt-dlp to download audio locally before processing

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

## ğŸ™ Credits

- [OpenAI Whisper](https://github.com/openai/whisper) - Speech recognition
- [pyannote.audio](https://github.com/pyannote/pyannote-audio) - Speaker diarization
- [FastAPI](https://fastapi.tiangolo.com/) - API server
- [yt-dlp](https://github.com/yt-dlp/yt-dlp) - URL audio extraction

---

<p align="center">
  Made with â¤ï¸ for privacy-conscious transcription
</p>
